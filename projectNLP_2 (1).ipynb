{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "path = path\n",
    "\n",
    "l = []\n",
    "l1 = []\n",
    "#importing data from the provided datasets\n",
    "def get_text(path_to_json):\n",
    "    with open(path_to_json) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        train = list(data.values())\n",
    "        l = []\n",
    "        l1 = []\n",
    "        for item in range(len(train)):\n",
    "            l.append(train[item]['text'])\n",
    "            l1.append(train[item]['label'])\n",
    "        \n",
    "    return l, l1  \n",
    "    \n",
    "#label-0 : Not a misinformtion\n",
    "#label-1 : It is a misinformation\n",
    "\n",
    "train_doc, train_label = get_text(os.path.join(path, 'train.json'))\n",
    "print(len(train_doc))\n",
    "dev_doc, dev_label = get_text(os.path.join(os.path.join(path, 'dev.json')))\n",
    "print(len(dev_doc))\n",
    "\n",
    "\n",
    "def get_test_data(path_to_json):\n",
    "    with open(path_to_json) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        train = list(data.values())\n",
    "        l = []\n",
    "        #l1 = []\n",
    "        for item in range(len(train)):\n",
    "            l.append(train[item]['text'])\n",
    "            #l1.append(train[item]['label'])\n",
    "        \n",
    "    return l \n",
    "test_doc = get_test_data(os.path.join(os.path.join(path, 'test-unlabelled.json')))\n",
    "print(len(test_doc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the external data set\n",
    "import json\n",
    "\n",
    "with open('external_data.json') as json_file:\n",
    "    external_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_doc + external_data\n",
    "y_train = train_label + [0]*1275 + [1]*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "\n",
    "import gensim\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    x1=[]\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "        \n",
    "new_train_X1 = list(sent_to_words(X_train))\n",
    "dev_X1 = list(sent_to_words(dev_doc))\n",
    "test_X1 = list(sent_to_words(test_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords removal\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "l = []\n",
    "def stopwords_remove(doc):\n",
    "    l = []\n",
    "    for i in range(len(doc)):\n",
    "        l.append([word for word in doc[i] if not word in stopwords])\n",
    "        l[i] = (' '.join([w for w in l[i]]))\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = stopwords_remove(new_train_X1)\n",
    "dev_1 = stopwords_remove(dev_X1)\n",
    "test_1 = stopwords_remove(test_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS Tagging\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "# 1. Init Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Lemmatization after POS Tagging\n",
    "def lempos(doc):\n",
    "    X = []\n",
    "    for i in range(len(doc)):\n",
    "        X.append([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(doc[i])])\n",
    "        X[i] = (' '.join([w for w in X[i]]))\n",
    "    return X\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = lempos(train_1)\n",
    "dev_set = lempos(dev_1)\n",
    "test_set = lempos(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "\n",
    "train_count = count_vect.fit_transform(train_set)\n",
    "dev_count = count_vect.transform(dev_set)\n",
    "test_count = count_vect.transform(test_set)\n",
    "\n",
    "tfidf_trans = TfidfTransformer()\n",
    "tc = tfidf_trans.fit_transform(train_count)\n",
    "dc = tfidf_trans.transform(dev_count)\n",
    "testc = tfidf_trans.transform(test_count)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashing Vectorizer\n",
    "\n",
    "\n",
    "\n",
    "hash_vect = HashingVectorizer()\n",
    "\n",
    "train_count1 = hash_vect.fit_transform(train_set)\n",
    "dev_count1 = hash_vect.transform(dev_set)\n",
    "test_count1 = hash_vect.transform(test_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "\n",
    "tf_vect = TfidfVectorizer(\n",
    "                         )\n",
    "\n",
    "train_count2 = tf_vect.fit_transform(train_set)\n",
    "dev_count2 = tf_vect.transform(dev_set)\n",
    "test_count2 = tf_vect.transform(test_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbors\n",
    "\n",
    "#knn = KNeighborsClassifier()\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "mod1 = knn.fit(train_count2, y_train)\n",
    "pred1 = mod1.predict(dev_count2)\n",
    "pred1_f = mod1.predict(test_count2)\n",
    "\n",
    "print(f1_score(dev_label, pred1, average='macro'))\n",
    "print(accuracy_score(dev_label, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error Analysis\n",
    "indices1 = [i for i in range(len(dev_label)) if dev_label[i] != pred1[i]]\n",
    "print(len(indices1))\n",
    "print(indices1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "gammas = [0.1, 1, 10, 100]\n",
    "cs = [0.1, 1, 10, 100, 1000]\n",
    "degrees = [0, 1, 2, 3, 4, 5, 6]\n",
    "SVM = svm.SVC(C=10)\n",
    "#SVM = svm.SVC(kernel='poly', gamma=0.1, C=10, degree=2)\n",
    "mod2 = SVM.fit(train_count2, y_train)\n",
    "pred2 = mod2.predict(dev_count2)\n",
    "pred2_f = mod2.predict(test_count2)\n",
    "\n",
    "print(f1_score(dev_label, pred2, average='macro'))\n",
    "print(accuracy_score(dev_label, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error Analysis\n",
    "indices5 = [i for i in range(len(dev_label)) if dev_label[i] != pred2[i]]\n",
    "print(len(indices5))\n",
    "print(indices5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes \n",
    "\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "MNB = naive_bayes.MultinomialNB(alpha=0.001, fit_prior=False)\n",
    "BNB = naive_bayes.BernoulliNB(alpha=0.001)\n",
    "GNB = naive_bayes.GaussianNB()\n",
    "mod3 = MNB.fit(tc, y_train)\n",
    "pred3 = mod3.predict(dc)\n",
    "pred3_f = mod3.predict(testc)\n",
    "\n",
    "print(f1_score(dev_label, pred3, average='macro'))\n",
    "print(accuracy_score(dev_label, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices4 = [i for i in range(len(dev_label)) if dev_label[i] != pred3[i]]\n",
    "print(len(indices4))\n",
    "print(indices4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "log_reg = LogisticRegression(C=1000, n_jobs=-1)\n",
    "mod4 = log_reg.fit(train_count2, y_train)\n",
    "pred4 = mod4.predict(dev_count2)\n",
    "pred4_f = mod4.predict(test_count2)\n",
    "\n",
    "print(f1_score(dev_label, pred4, average='macro'))\n",
    "print(accuracy_score(dev_label, pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error Analysis\n",
    "indices = [i for i in range(len(dev_label)) if dev_label[i] != pred4[i]]\n",
    "print(len(indices))\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#RFC = RandomForestClassifier()\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200, 300]\n",
    "maxfeat = ['sqrt', 'log2', None]\n",
    "#for nest in n_estimators:\n",
    "#    for mf in maxfeat:\n",
    "RFC = RandomForestClassifier(n_estimators=200, \n",
    "                               max_features = 'sqrt', \n",
    "                               n_jobs=-1, verbose = 1, random_state=1)\n",
    "mod5 = RFC.fit(train_count2, y_train)\n",
    "pred5 = mod5.predict(dev_count2)\n",
    "pred5_f = mod5.predict(test_count2)\n",
    "print(f1_score(dev_label, pred5, average='macro'))\n",
    "print(accuracy_score(dev_label, pred5))\n",
    "       # print(\"The parameters for this model are: \"+ str(nest), str(mf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices6 = [i for i in range(len(dev_label)) if dev_label[i] != pred5[i]]\n",
    "print(len(indices6))\n",
    "print(indices6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimators = [ #IsolationForest(n_jobs=-1)),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=50, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=-1, verbose = 1)),\n",
    "    ('lg', LogisticRegression(C=1000))\n",
    "   # ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    #('svm', svm.SVC(C=1))\n",
    "    #('nbm', naive_bayes.MultinomialNB(alpha=0.001, fit_prior=False))\n",
    "    ]\n",
    "clf1 = VotingClassifier(estimators=estimators, n_jobs=-1)\n",
    "\n",
    "mod8 = clf1.fit(train_count2, y_train)\n",
    "pred8 = mod8.predict(dev_count2)\n",
    "pred8_f = mod8.predict(test_count2)\n",
    "\n",
    "print(f1_score(dev_label, pred8, average='macro'))\n",
    "print(accuracy_score(dev_label, pred8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices9 = [i for i in range(len(dev_label)) if dev_label[i] != pred8[i]]\n",
    "print(len(indices9))\n",
    "print(indices9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "estimators = [#('xgb', XGBClassifier()), \n",
    "   # ('etc', ExtraTreesClassifier()),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=50, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=-1, verbose = 2, random_state=42)),\n",
    "    ('lg', LogisticRegression(C=10000)),\n",
    "    ('svm', svm.SVC(C=1))\n",
    "     ]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator = svm.SVC(C=1), cv=10,\n",
    "                         passthrough=True  #, stack_method='predict_proba'\n",
    "                     )\n",
    "\n",
    "mod5 = clf.fit(train_count2, y_train)\n",
    "pred5 = mod5.predict(dev_count2)\n",
    "pred5_f = mod5.predict(test_count2)\n",
    "\n",
    "print(f1_score(dev_label, pred5, average='macro'))\n",
    "print(accuracy_score(dev_label, pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices6 = [i for i in range(len(dev_label)) if dev_label[i] != pred5[i]]\n",
    "print(len(indices6))\n",
    "print(indices6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create format for the test submission Files\n",
    "def str_json_format(results):\n",
    "    strings = \"{\"\n",
    "    for i, j in enumerate(list(results)):\n",
    "        j = str(j)\n",
    "        i = str(i)\n",
    "        strings += \"\\\"test-\" + i + \"\\\"\" + \":{\\\"label\\\":\" + j + \"},\"\n",
    "    strings = strings[:-1] + \"}\"\n",
    "    \n",
    "    return strings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = list(chain(*dev_set))\n",
    "print(len(X3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(X3).most_common(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
